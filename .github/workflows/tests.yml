# GitHub Actions Workflow for College Football Ranking System Tests
# Runs on push and pull requests to ensure code quality

name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    name: Run Test Suite
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: ['3.11']

    steps:
      # Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Set up Python
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      # Cache pip dependencies
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      # Install Playwright browsers for E2E tests
      - name: Install Playwright browsers
        run: |
          python -m playwright install chromium

      # Run unit tests
      - name: Run unit tests
        run: |
          pytest -m unit -v --tb=short

      # Run integration tests
      - name: Run integration tests
        run: |
          pytest -m integration -v --tb=short

      # Run all tests with coverage (except E2E)
      - name: Run tests with coverage
        run: |
          pytest -m "not e2e" --cov=. --cov-report=xml --cov-report=term-missing

      # Upload coverage to Codecov (optional)
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      # Archive test results
      - name: Archive test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            htmlcov/
            .coverage
          retention-days: 7

  # Optional: E2E tests job (runs separately, requires server)
  e2e-test:
    name: Run E2E Tests
    runs-on: ubuntu-latest
    needs: test  # Only run if unit/integration tests pass
    timeout-minutes: 30  # Prevent hung tests from running forever

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          python -m playwright install chromium

      # Create and seed test database for E2E tests
      - name: Setup test database
        run: |
          python3 << 'EOF'
          from database import Base, engine, SessionLocal
          from models import Season, Team, ConferenceType
          from datetime import datetime

          # Create tables
          Base.metadata.create_all(bind=engine)

          # Seed minimal data
          db = SessionLocal()
          try:
              # Add current season
              season = Season(
                  year=2024,
                  is_active=True,
                  current_week=10,
                  start_date=datetime(2024, 8, 24),
                  end_date=datetime(2025, 1, 20)
              )
              db.add(season)

              # Add a few test teams
              teams = [
                  Team(name="Alabama", conference=ConferenceType.POWER_5, is_fcs=False, elo_rating=1800.0),
                  Team(name="Georgia", conference=ConferenceType.POWER_5, is_fcs=False, elo_rating=1780.0),
                  Team(name="Ohio State", conference=ConferenceType.POWER_5, is_fcs=False, elo_rating=1750.0),
              ]
              for team in teams:
                  db.add(team)

              db.commit()
              print("âœ“ Test database seeded successfully")
          finally:
              db.close()
          EOF

      # Start FastAPI server in background
      - name: Start FastAPI server
        run: |
          python3 main.py &
          # Wait for server to be ready (max 30 seconds)
          for i in {1..30}; do
            if curl -s http://localhost:8000/ > /dev/null 2>&1; then
              echo "Server is ready!"
              break
            fi
            echo "Waiting for server... ($i/30)"
            sleep 1
          done
        env:
          PYTHONUNBUFFERED: 1

      # Run E2E tests
      - name: Run E2E tests
        run: |
          pytest -m e2e -v --tb=short

      # Take screenshots on failure
      - name: Archive E2E screenshots
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-screenshots
          path: screenshots/
          retention-days: 7
